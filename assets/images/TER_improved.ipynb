{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Linear Regression Tutorial (Improved)\n", "\n", "Author: Andrew Andrade (adapted and improved by ChatGPT)\n", "\n", "This notebook is an upgraded version of your original TER notebook. It includes:\n", "- Bug fixes and compatibility updates\n    - Reshape fixes for sklearn\n    - Deprecated parameter updates\n- Additional explanations and comments\n- Extra plots, metrics (MSE, R\u00b2)\n- Horizontal residuals and orthogonal regression\n- Statsmodels summary\n"]}, {"cell_type": "code", "execution_count": 1, "metadata": {}, "outputs": [], "source": ["import matplotlib.pyplot as plt\n", "import numpy as np\n", "import pandas as pd\n", "from math import log\n", "import warnings\n", "warnings.filterwarnings('ignore')\n", "\n", "# Try to import sklearn and scipy; if not present, print helpful message\n", "try:\n", "    from sklearn import linear_model\n", "except Exception as e:\n", "    print('sklearn not available. If running locally, install with: pip install scikit-learn')\n", "\n", "try:\n", "    import statsmodels.api as sm\n", "except Exception:\n", "    print('statsmodels not available. Install with: pip install statsmodels')\n", "\n", "try:\n", "    from scipy.odr import Model, Data, ODR\n", "    from scipy.stats import linregress\n", "except Exception:\n", "    print('scipy not available. Install with: pip install scipy')\n", "\n", "%matplotlib inline\n"]}, {"cell_type": "code", "execution_count": 2, "metadata": {}, "outputs": [], "source": ["# Load dataset (ensure anscombe_i.csv is in the same folder)\n", "import os\n", "if not os.path.exists('anscombe_i.csv'):\n", "    # create anscombe_i.csv from the classic Anscombe I data if missing\n", "    df = pd.DataFrame({'x':[10,8,13,9,11,14,6,4,12,7,5],\n", "                       'y':[8.04,6.95,7.58,8.81,8.33,9.96,7.24,4.26,10.84,4.82,5.68]})\n", "    df.to_csv('anscombe_i.csv', index=False)\n", "anscombe_i = pd.read_csv('anscombe_i.csv')\n", "anscombe_i.head()\n"]}, {"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": ["# Scatter plot of the data\n", "plt.figure(figsize=(6,4))\n", "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n", "plt.xlabel('X')\n", "plt.ylabel('Y')\n", "plt.title('Anscombe I - Scatter')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Fit Linear Regression using sklearn"]}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [], "source": ["regr_i = linear_model.LinearRegression()\n", "X = anscombe_i['x'].values.reshape(-1,1)\n", "y = anscombe_i['y'].values.reshape(-1,1)\n", "regr_i.fit(X,y)\n", "print('Coefficient (m):', float(regr_i.coef_[0]))\n", "print('Intercept (b):', float(regr_i.intercept_))\n", "mse = np.mean((regr_i.predict(X)-y)**2)\n", "print('Residual sum of squares (MSE): %.4f' % mse)\n", "print('R^2 score: %.4f' % regr_i.score(X,y))\n", "plt.figure(figsize=(6,4))\n", "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n", "plt.plot(X, regr_i.predict(X), color='green', linewidth=2, label='OLS fit')\n", "plt.xlabel('X')\n", "plt.ylabel('Y')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Residuals and Distribution"]}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [], "source": ["from numpy import polyfit\n", "k,d = polyfit(anscombe_i.x, anscombe_i.y, 1)\n", "yfit = k*anscombe_i.x + d\n", "residual = anscombe_i.y - yfit\n", "print('Polyfit slope, intercept:', k, d)\n", "plt.figure(figsize=(6,4))\n", "plt.scatter(anscombe_i.x, residual)\n", "plt.axhline(0, color='red', linestyle='--')\n", "plt.xlabel('X')\n", "plt.ylabel('Residual (y - yhat)')\n", "plt.title('Residuals vs X')\n", "plt.show()\n", "\n", "plt.figure(figsize=(6,4))\n", "plt.hist(residual, bins=10, density=True, alpha=0.7)\n", "try:\n", "    from scipy.stats import norm\n", "    xs = np.linspace(residual.min(), residual.max(), 200)\n", "    plt.plot(xs, norm.pdf(xs, residual.mean(), residual.std()), 'k--')\n", "except Exception:\n", "    pass\n", "plt.title('Residual distribution')\n", "plt.xlabel('Residual')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Statsmodels OLS and Summary"]}, {"cell_type": "code", "execution_count": 6, "metadata": {}, "outputs": [], "source": ["try:\n", "    X_sm = sm.add_constant(anscombe_i.x)\n", "    model = sm.OLS(anscombe_i.y, X_sm).fit()\n", "    print(model.summary())\n", "except Exception as e:\n", "    print('statsmodels unavailable or error:', e)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Horizontal residuals (regress X on Y)"]}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": ["k2,d2 = polyfit(anscombe_i.y, anscombe_i.x, 1)\n", "xfit = k2*anscombe_i.y + d2\n", "plt.figure(figsize=(6,4))\n", "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n", "plt.plot(xfit, anscombe_i.y, color='blue', label='Horizontal fit (X~Y)')\n", "plt.xlabel('X')\n", "plt.ylabel('Y')\n", "plt.legend()\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Total Least Squares (Orthogonal Distance Regression)"]}, {"cell_type": "code", "execution_count": 8, "metadata": {}, "outputs": [], "source": ["def fit_function(p, x):\n", "    return p[0]*x + p[1]\n", "def orthoregress(x, y):\n", "    lr = linregress(x, y)\n", "    model = Model(fit_function)\n", "    data = Data(x, y)\n", "    od = ODR(data, model, beta0=lr[0:2])\n", "    out = od.run()\n", "    return out.beta\n", "try:\n", "    m_ortho, b_ortho = orthoregress(anscombe_i.x.values, anscombe_i.y.values)\n", "    y_ortho = m_ortho*anscombe_i.x + b_ortho\n", "    plt.figure(figsize=(6,4))\n", "    plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n", "    plt.plot(anscombe_i.x, y_ortho, 'r', label='Orthogonal fit')\n", "    plt.legend()\n", "    plt.show()\n", "except Exception as e:\n", "    print('scipy.odr not available or error:', e)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Compare all three lines"]}, {"cell_type": "code", "execution_count": 9, "metadata": {}, "outputs": [], "source": ["plt.figure(figsize=(7,5))\n", "plt.scatter(anscombe_i.x, anscombe_i.y, color='black')\n", "plt.plot(anscombe_i.x, yfit, 'g', label='Vertical residuals (OLS)')\n", "plt.plot(xfit, anscombe_i.y, 'b', label='Horizontal residuals')\n", "try:\n", "    plt.plot(anscombe_i.x, y_ortho, 'r', label='Orthogonal')\n", "except NameError:\n", "    pass\n", "plt.legend()\n", "plt.xlabel('X')\n", "plt.ylabel('Y')\n", "plt.title('Comparison of regression fits')\n", "plt.show()\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Key Takeaways\n\n1. Check assumptions before applying linear regression.\n2. Understand when vertical, horizontal, or orthogonal residual minimization is appropriate.\n3. Use diagnostics (residual plots, distributions, R\u00b2, p-values) to evaluate fits.\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Extra: Predict a house price example (Homework hint)\n\nThis section demonstrates transforming variables (log/power) and fitting a simple linear model \u2014 left as an exercise in the original notebook."]}], "metadata": {"kernelspec": {"display_name": "Python 3 (ipykernel)", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}